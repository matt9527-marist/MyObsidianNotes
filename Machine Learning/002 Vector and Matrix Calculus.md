## Scalar Derivatives 

Instantaneous Rate of Change
![[Pasted image 20250901160921.png]]

**Gradient** the gradient vector is a 2D vector that represents or points toward the direction of the rate of fastest increase. If the gradient of the function is non-zero at a point p, the direction of the gradient is the direction in which the funtion increases most quickly from p, and the magnitude of the gradient is the rate of increase in that direction. 

![[Pasted image 20250901164453.png]]

The gradient plays a fundamental role in **optimization** theory, and therefore in machine learning, where it is used to maximize a function by gradient ascent (or by its inverse, minimize a loss function by gradient descent)


