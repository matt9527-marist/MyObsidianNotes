• MPI -> Message Passing Interface  
• Enables inter-process communication  
• Supports large-scale simulations across nodes  
• Ubiquitous in high-performance computing (HPC)  
• Launched in 1994, now MPI 3.1 (2015)  
• Major implementations: MPICH, OpenMPI  
• Used in: physics, ML, autonomous vehicles, etc.

**Core Concepts and Usage**
• Sending messages between processes  
• Using collective MPI communication patterns  
• Exchanging data between meshes on separate processes  
• Creating custom MPI data types  
• Using MPI Cartesian topology  
• Writing hybrid MPI + OpenMP applications

**Basic Send and Receive Prototypes**
```c++
MPI_Send(void *data, int count, MPI_Datatype datatype,  
int dest, int tag, MPI_COMM comm) 
 
MPI_Recv(void *data, int count, MPI_Datatype datatype,  
int source, int tag, MPI_COMM comm, MPI_Status  
*status)
```

• Blocking send/recv may deadlock if not carefully ordered
• Non-blocking (Isend/Irecv) allows safe overlapping communication & computation
